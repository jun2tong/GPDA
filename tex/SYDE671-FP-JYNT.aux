\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{kim2019unsupervised}
\citation{kim2019unsupervised}
\citation{khan2018fast}
\citation{kim2019unsupervised}
\citation{ben2010theory}
\citation{sun2016deep}
\citation{rebuffi2017learning}
\citation{courty2017joint}
\citation{benaim2017one}
\citation{liu2017unsupervised}
\citation{liu2016coupled}
\citation{kim2019unsupervised}
\citation{kim2019unsupervised}
\@writefile{brf}{\backcite{kim2019unsupervised}{{1}{(document)}{Doc-Start}}}
\@writefile{brf}{\backcite{kim2019unsupervised}{{1}{(document)}{Doc-Start}}}
\@writefile{brf}{\backcite{khan2018fast}{{1}{(document)}{Doc-Start}}}
\@writefile{brf}{\backcite{kim2019unsupervised}{{1}{(document)}{Doc-Start}}}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Work}{1}{section.2}\protected@file@percent }
\@writefile{brf}{\backcite{ben2010theory}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{sun2016deep}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{rebuffi2017learning}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{courty2017joint}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{benaim2017one}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{liu2017unsupervised}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{liu2016coupled}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{kim2019unsupervised}{{1}{2}{section.2}}}
\@writefile{brf}{\backcite{kim2019unsupervised}{{1}{2}{section.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Unsupervised Domain Adaptation}{1}{section.3}\protected@file@percent }
\citation{amari1998natural}
\citation{pascanu2013revisiting}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Gaussian Process Classifier}{2}{subsection.3.1}\protected@file@percent }
\newlabel{eq:prior}{{1}{2}{\hskip -1em.~Gaussian Process Classifier}{equation.3.1}{}}
\newlabel{eq:likfunc}{{2}{2}{\hskip -1em.~Gaussian Process Classifier}{equation.3.2}{}}
\newlabel{eq:targetpost}{{3}{2}{\hskip -1em.~Gaussian Process Classifier}{equation.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Deep Kernel Trick}{2}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Variational Inference}{2}{subsection.3.3}\protected@file@percent }
\newlabel{eq:ELBO}{{5}{2}{\hskip -1em.~Variational Inference}{equation.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Improving UDA via the Natural Gradient}{2}{section.4}\protected@file@percent }
\@writefile{brf}{\backcite{amari1998natural}{{2}{4}{section.4}}}
\@writefile{brf}{\backcite{pascanu2013revisiting}{{2}{4}{section.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Two Results from Statistics}{2}{subsection.4.1}\protected@file@percent }
\citation{khan2018fast}
\bibstyle{ieee}
\bibdata{Fall2017_ProjectFinal_ProjectReportTemplate}
\bibcite{amari1998natural}{1}
\bibcite{ben2010theory}{2}
\bibcite{benaim2017one}{3}
\newlabel{eq:KL-tsapprox}{{6}{3}{\hskip -1em.~Two Results from Statistics}{equation.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Steepest Descent Directions in \(D_{KL}\) balls}{3}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Experimental Result}{3}{section.5}\protected@file@percent }
\@writefile{brf}{\backcite{khan2018fast}{{3}{5}{section.5}}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The graph shows the loss versus epoch iteration of two optimization algorithm, Vadam and Adam. The blue is Vadam which uses natural gradient for update clearly converges to a loss quicker than Adam in red.}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:vadam_compare}{{1}{3}{The graph shows the loss versus epoch iteration of two optimization algorithm, Vadam and Adam. The blue is Vadam which uses natural gradient for update clearly converges to a loss quicker than Adam in red}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Discussion}{3}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}\hskip -1em.\nobreakspace  {}Conclusion}{3}{section.7}\protected@file@percent }
\bibcite{courty2017joint}{4}
\bibcite{khan2018fast}{5}
\bibcite{kim2019unsupervised}{6}
\bibcite{liu2017unsupervised}{7}
\bibcite{liu2016coupled}{8}
\bibcite{pascanu2013revisiting}{9}
\bibcite{rebuffi2017learning}{10}
\bibcite{sun2016deep}{11}
