\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Domain Adaptation}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.\nobreakspace  {}Gaussian Process Classifier}{1}{subsection.1.1}\protected@file@percent }
\newlabel{eq:prior}{{1}{1}{\hskip -1em.~Gaussian Process Classifier}{equation.1.1}{}}
\newlabel{eq:likfunc}{{2}{1}{\hskip -1em.~Gaussian Process Classifier}{equation.1.2}{}}
\newlabel{eq:targetpost}{{3}{1}{\hskip -1em.~Gaussian Process Classifier}{equation.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\hskip -1em.\nobreakspace  {}Deep Kernel Trick}{1}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Variational Inference}{1}{section.2}\protected@file@percent }
\citation{amari1998natural}
\citation{pascanu2013revisiting}
\citation{khan2018fast}
\newlabel{eq:ELBO}{{5}{2}{\hskip -1em.~Variational Inference}{equation.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Natural Gradient}{2}{section.3}\protected@file@percent }
\@writefile{brf}{\backcite{amari1998natural}{{2}{3}{section.3}}}
\@writefile{brf}{\backcite{pascanu2013revisiting}{{2}{3}{section.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Two Results from Statistics}{2}{subsection.3.1}\protected@file@percent }
\newlabel{eq:KL-tsapprox}{{6}{2}{\hskip -1em.~Two Results from Statistics}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Steepest Descent Directions in \(D_{KL}\) balls}{2}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Experimental Result}{2}{section.4}\protected@file@percent }
\@writefile{brf}{\backcite{khan2018fast}{{2}{4}{section.4}}}
\bibstyle{ieee}
\bibdata{references}
\bibcite{amari1998natural}{1}
\bibcite{khan2018fast}{2}
\bibcite{pascanu2013revisiting}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The graph shows the loss versus epoch iteration of two optimization algorithm, Vadam and Adam. The blue is Vadam which uses natural gradient for update clearly converges to a loss quicker than Adam in red.}}{3}{figure.1}\protected@file@percent }
\newlabel{fig:vadam_compare}{{1}{3}{The graph shows the loss versus epoch iteration of two optimization algorithm, Vadam and Adam. The blue is Vadam which uses natural gradient for update clearly converges to a loss quicker than Adam in red}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Discussion}{3}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Conclusion}{3}{section.6}\protected@file@percent }
